{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy's Matcher\n",
    "\n",
    "Based on **Dr. William Mattingly** video: https://www.youtube.com/watch?v=dIUTsFT2MeQ&t\n",
    "\n",
    "and his Jupyter Book: http://spacy.pythonhumanities.com/02_02_matcher.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexeme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **lexeme** in spaCy represents a word in a text and includes essential linguistic attributes. It serves as a unit of vocabulary and is associated with a unique integer ID. Lexemes store information such as the word's text, part-of-speech tag, lemma, morphological features and more. They enable efficient and memory-friendly text processing by serving as shared references to the vocabulary, minimizing duplication of linguistic information. Working with lexemes in spaCy enhances performance and reduces memory usage in natural language processing tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LIKE_EMAIL\": True}]\n",
    "matcher.add(\"EMAIL_ADDRESS\", [pattern])\n",
    "doc = nlp(\"This is an email address: wiktorflorianwf@gmail.com\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme: 16571425990740197027, start token: 6, end token: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lexeme: {matches[0][0]}, start token: {matches[0][1]}, end token: {matches[0][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme: EMAIL_ADDRESS, start token: IS_SPACE, end token: IS_TITLE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lexeme: {nlp.vocab[matches[0][0]].text}, start token: {nlp.vocab[matches[0][1]].text}, end token: {nlp.vocab[matches[0][2]].text}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atrributes of the Matcher"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **ORTH**: The exact verbatim of a token (string). the token's \"orthographic\" form, which is the exact verbatim representation of the token as it appears in the original text. It preserves the original casing, punctuation, and any other textual details without modifications. The **ORTH** attribute is useful when you want to precisely match or manipulate the token's original form. \n",
    "+ **TEXT**: The exat verbatim of a token (string). Normalized form of token, typically returns the lowercase version of the token, regardless of its original casing. The **TEXT** atrribute is useful when you want to compare or process tokens in a case-insensitive manner or when you want to apply general text processing operations.\n",
    "+ **LOWER**: The lowercase form of the token text (string).\n",
    "+ **LENGTH**: The length of the token text (integer).\n",
    "+ **IS_ALPHA**: Indicates if the token consists of alphabetic characters.\n",
    "+ **IS_ASCII**: Indicates if the token consists of ASCII characters.\n",
    "+ **IS_DIGIT**: Indicates if the token consists of digits.\n",
    "+ **IS_LOWER**: Indicates if the token is in lowercase.\n",
    "+ **IS_UPPER**: Indicates if the token is in uppercase.\n",
    "+ **IS_TITLE**: Indicates if the token is in title case.\n",
    "+ **IS_PUNCT**: Indicates if the token is a punctuaction mark.\n",
    "+ **IS_SPACE**: Indicates if the token is a space character.\n",
    "+ **IS_STOP**: Indicates if the token is a stop word.\n",
    "+ **IS_SENT_START**: Indicates if the token starts a sentence.\n",
    "+ **LIKE_NUM**: Indicates if the token resembles a numeric value.\n",
    "+ **LIKE_URL**: Indicates if the token resembles a URL.\n",
    "+ **LIKE_EMAIL**: Indicates if the token resembles an email address.\n",
    "+ **SPACY**: The unique identifier of the spaCy model.\n",
    "+ **POS**: The part-of-speech tag of token.\n",
    "+ **TAG**: The fine-grained part-of-speech tag of token.\n",
    "+ **MORPH**: The morphological features of the token.\n",
    "+ **DEP**: The syntactic dependency relation of the token.\n",
    "+ **LEMMA**: The base form or lemma of the token\n",
    "+ **SHAPE**: The shape or pattern of the token.\n",
    "+ **ENT_TYPE**: The named entity type of the token.\n",
    "+ **_**: Custom extension attributes (a dictionaryy of strin keys and any values).\n",
    "+ **OP**: The operator used to define the matching pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
