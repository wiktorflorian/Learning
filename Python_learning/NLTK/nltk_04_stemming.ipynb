{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Stemming\n",
    "\n",
    "Based on **Stats Wire** video: https://www.youtube.com/watch?v=I8HNBp8ReLg&list=PLBSCvBlTOLa_wS8iy84DfyizdSs7ps7L5&index=7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Normalizing refers to the process of transforming text data into a standard, consisten format. It involves various steps such as:\n",
    "+ **Converting all text to lowercase**: This ensures that the same word in different cases is treated as identical (e.g., \"apple\" and \"Apple\").\n",
    "+ **Removing punctuation**: Punctuation marks are eliminated from the text as tey do not contribute to the meaning of the words.\n",
    "+ **Removing stop words**: Stop words are common words like \"a\", \"an\", \"the\", etc., that occur frequently in a language but typically do not carry significant meaning. Removing stop words helps reduce noise and focus on important content words.\n",
    "+ **Removing numerical digits or special characters**: Numbers or special characters that do not carry specific meaning in the context of text analysis can be removed. \n",
    "+ **Removing HTML tags or URLs**: If the text contains HTML tags or URLs, they can be stripped out.\n",
    "+ **Handling contractions**: Converting contractions like \"don't\" to \"do not\"  ensures consistency in word usage.\n",
    "\n",
    "The goal of normalization is to create a cleaner and more standardized representation of the text, making it easier for further analysis and processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is a technique for reducing words to their base or root form, known as the **stem**. The stem may not be an actual word itself, but it represents the core meaning of the word. Stemming helps to reduce inflected or derived words to a common form so that variations of the same word are treated as identical. Stemming algorithms apply linguistic rules nad heuristics to strip off prefixes and suffixes from words. aiming to identify the common stem. For example, stemming would reduce words like \"running\", \"runs\", and \"ran\" to the common stem \"run\". Thissimplification of words can help with tasks such as information retrieval, text classification, and clustering. It's important to note that stemming is a rule-based process and may not always produce accurate results. It can sometimes generate stems that are not actual words. In such cases, Lemmatization, which considers the word's part of speech and context to determine its base form (**lemma**), can be more linguistically accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Work works working workings worked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work works working workings worked\n"
     ]
    }
   ],
   "source": [
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work works working workings worked'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work', 'works', 'working', 'workings', 'worked']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.lower().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = text1.lower().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'works', 'working', 'workings', 'worked']\n"
     ]
    }
   ],
   "source": [
    "print(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving PorterStemmer class in object\n",
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work', 'work', 'work', 'work', 'work']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "[porter.stem(w) for w in words1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
