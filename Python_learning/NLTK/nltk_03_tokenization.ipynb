{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Based on **Stats Wire** video: https://www.youtube.com/watch?v=niKMwO8NIiM&list=PLBSCvBlTOLa_wS8iy84DfyizdSs7ps7L5&index=4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking down a text or a sequence of characters into smaller units called tokens. Tokens can be individual words, sentences, or even subwords depending on the level of granularity desired. The purpose of tokenization is to provide a structure representaton of text data, making it easier to process, analyze, and understand.\n",
    "\n",
    "In natural language processing (NLP), tokenization is often the first step in text preprocessing. It helps in converting unstructured text data into a structured format that can be used for various NLP tasks such as text classification, information retrieval, machine translation, and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"NLTK is a leading platform for building Python programs to work with human language data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK is a leading platform for building Python programs to work with human language data.\n"
     ]
    }
   ],
   "source": [
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'building',\n",
       " 'Python',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'human',\n",
       " 'language',\n",
       " 'data.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'building',\n",
       " 'Python',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'human',\n",
       " 'language',\n",
       " 'data',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should use word_tokenize instead of splitting since it is desinged for tokenization, but split is faster\n",
    "nltk.word_tokenize(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.word_tokenize(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Python is an open source. Python is a programming language. Python is free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is an open source. Python is a programming language. Python is free\n"
     ]
    }
   ],
   "source": [
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python is an open source.',\n",
       " 'Python is a programming language.',\n",
       " 'Python is free']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.sent_tokenize(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"Python is an open source. Python is a programming language. Python in U.S. is free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python is an open source.',\n",
       " 'Python is a programming language.',\n",
       " 'Python in U.S. is free']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
