{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52e0282-72d1-4fb9-b8aa-c146842241b2",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader\n",
    "\n",
    "Based on **Patric Loeber** video: https://www.youtube.com/watch?v=c36lUUr864M&t=7076s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5071b-e52b-458f-ba63-a69257e7ccde",
   "metadata": {},
   "source": [
    "## Not good approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae349e4-2be2-4d4a-9e00-6020baac2cc3",
   "metadata": {},
   "source": [
    "If we first load all the training samples and we try to compute them all at once we will face long computational problems. Because callculating gradients of all the samples will take to much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a2f29-55ea-4500-8ffe-44b0de32e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.loadtxt('wine.csv')\n",
    "# training loop\n",
    "for epoch in range(1000):\n",
    "    w, y = data\n",
    "    # forward + backward + weights updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955b0ef-7389-4e95-95da-e130f7b6ee52",
   "metadata": {},
   "source": [
    "## Good approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85f1c0-6f47-4902-9395-8c1fc063ca01",
   "metadata": {},
   "source": [
    "When we want to analize the **BIG** datasets we need somehow deal with them. So we can't just load all the data at once. We have to divide the saples into so-called smaller batches and then our training loop looks like one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df59db6-6c33-4173-9cc7-130159a7b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(1000):\n",
    "    # loop over all batches\n",
    "    for i in range(total_batches):\n",
    "        x_batch, y_batch = ...\n",
    "        \n",
    "# --> use DataSet and DataLoader to load wine.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e3584-0e1a-47bb-b703-5aa133a56396",
   "metadata": {},
   "source": [
    "## Batch training terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316fcfb4-1542-490c-9ae0-7c9b1a102554",
   "metadata": {},
   "source": [
    "+ epoch - one forward and backward pass of ALL training samples\n",
    "+ batch_size - number of training samples in one forward and backward pass\n",
    "+ number of iterations - number of passes, each pas usig [batch_size] number fo samples\n",
    "\n",
    "e.g. 100 samples, batch_size=20 --> 100/20 = 5 iterations for 1 epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed91243-ceba-4c21-ac0b-c8adbd8d51f5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56309027-ce47-48a7-8954-664e5ba63267",
   "metadata": {},
   "source": [
    "First row in our Dataset is the header. We want to calculate or to predict the wine category. We have three different wine categories: 1, 2 and 3. The class label is in the very first column and all the other columns are the features. We will load this dataset and split columns into X and y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9307e4-20e6-4537-8632-83c73d4d9ff3",
   "metadata": {},
   "source": [
    "## Impelementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c113d5-61dc-4caa-8526-4fd67469f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./wine_data/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        # all rows and all columns without first one (y)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee467ee9-a083-4c5b-92a6-1bce0e0fa78a",
   "metadata": {},
   "source": [
    "## Creating dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ba2f1a-6a26-4f43-b261-2e440ded2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WineDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949920af-3f12-4958-a885-2397f6cafeeb",
   "metadata": {},
   "source": [
    "## unpacking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67271cd0-81a0-476f-a354-bda46bcf93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = dataset[0]\n",
    "features, labels = first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988d9262-861c-4323-9676-29e71e80829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81186233-de66-4407-b8ce-48eecdf2c847",
   "metadata": {},
   "source": [
    "## Using Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2408acf-cb16-4cda-abe5-e24542efb149",
   "metadata": {},
   "source": [
    "Shuffle is an optional argument which reshufles data after each epoch. The num_workes argument is used for multi-processing data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b11385d-e523-4df1-9257-845aa28cc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True) #, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704c69b0-ec2f-4fd8-a0a7-ee196f9cee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3630e+01, 1.8100e+00, 2.7000e+00, 1.7200e+01, 1.1200e+02, 2.8500e+00,\n",
      "         2.9100e+00, 3.0000e-01, 1.4600e+00, 7.3000e+00, 1.2800e+00, 2.8800e+00,\n",
      "         1.3100e+03],\n",
      "        [1.3360e+01, 2.5600e+00, 2.3500e+00, 2.0000e+01, 8.9000e+01, 1.4000e+00,\n",
      "         5.0000e-01, 3.7000e-01, 6.4000e-01, 5.6000e+00, 7.0000e-01, 2.4700e+00,\n",
      "         7.8000e+02],\n",
      "        [1.3070e+01, 1.5000e+00, 2.1000e+00, 1.5500e+01, 9.8000e+01, 2.4000e+00,\n",
      "         2.6400e+00, 2.8000e-01, 1.3700e+00, 3.7000e+00, 1.1800e+00, 2.6900e+00,\n",
      "         1.0200e+03],\n",
      "        [1.1030e+01, 1.5100e+00, 2.2000e+00, 2.1500e+01, 8.5000e+01, 2.4600e+00,\n",
      "         2.1700e+00, 5.2000e-01, 2.0100e+00, 1.9000e+00, 1.7100e+00, 2.8700e+00,\n",
      "         4.0700e+02]]) tensor([[1.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1919bb-fc0d-4539-b905-100814990bfd",
   "metadata": {},
   "source": [
    "## Dummy training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9f2af30-e780-44e0-b57e-668ac9407232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 178, number of iterations: 45\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "# number of iterations in one epoch\n",
    "n_iterations = math.ceil(total_samples / 4) # where 4 is a batch size\n",
    "print(f\"Number of samples: {total_samples}, number of iterations: {n_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7020ede9-e19d-4c3c-936e-c67360ca5f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 2, step: 5 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 10 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 15 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 20 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 25 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 30 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 35 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 40 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1 / 2, step: 45 / 45, inputs: torch.Size([2, 13])\n",
      "epoch: 2 / 2, step: 5 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 10 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 15 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 20 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 25 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 30 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 35 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 40 / 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2 / 2, step: 45 / 45, inputs: torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward, update weights\n",
    "        # normaly we would like to do things above but for example we will print information about batch\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"epoch: {epoch +1} / {num_epochs}, step: {i+1} / {n_iterations}, inputs: {inputs.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
