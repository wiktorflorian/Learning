{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67fdbbe-cb5b-456f-b254-c2898841ec3f",
   "metadata": {},
   "source": [
    "# Tensor Basics\n",
    "\n",
    "Based on **Patric Loeber** video: https://www.youtube.com/watch?v=c36lUUr864M&t=450s\n",
    "\n",
    "## Tensor\n",
    "\n",
    "### Notes\n",
    "\n",
    "tensors can have different dimensions: 1d, 2d, 3d or more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fc7c2-ab72-48b9-974b-070b0ccb953e",
   "metadata": {},
   "source": [
    "## Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f38fa46-2ea0-448b-ae0b-ea4cdaee2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7afbf5d9-5413-4e0a-9fd8-91229913ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "# empty tensor, we have to specify the size\n",
    "# like 1d vector with 3 elements\n",
    "x = torch.empty(3)\n",
    "# like 2d matrix\n",
    "x = torch.empty(2, 3)\n",
    "# 3d tensor\n",
    "x = torch.empty(2, 2, 3)\n",
    "# 4d tensor\n",
    "x = torch.empty(2, 2, 2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "869b209d-14eb-4c2a-9bf9-b95f14f41117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0404, 0.7200],\n",
      "        [0.6809, 0.9980]])\n"
     ]
    }
   ],
   "source": [
    "# tensor with random values\n",
    "x = torch.rand(2, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b137c3-d68b-448f-8b51-fd74d4f8dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor filled with 0'es\n",
    "x = torch.zeros(2, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a25e2491-bd80-4efc-99dc-8e2868053c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor filled with 1's\n",
    "x = torch.ones(2,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f81e350-f9e3-4306-8c18-88997b6bf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# we can give it specific data type, by default float32\n",
    "x = torch.ones(2,2, dtype=torch.float16) # int, double, torch.float16\n",
    "# checking tensor type\n",
    "print(x.dtype)\n",
    "# checking tensor size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f257480-4ea7-498b-81b0-68cb2295eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "# creating tensor from data\n",
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061eb78-6557-4666-b617-4a8cc87f945e",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c79f92e-f644-42fe-b689-accc22d9be1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5338, 0.1326],\n",
      "        [0.6988, 0.0970]])\n",
      "tensor([[0.0869, 0.1482],\n",
      "        [0.3593, 0.6663]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec3d8309-633a-42ba-88cc-da393acf1029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6207, 0.2808],\n",
      "        [1.0582, 0.7633]])\n",
      "tensor([[0.6207, 0.2808],\n",
      "        [1.0582, 0.7633]])\n",
      "tensor([[0.6207, 0.2808],\n",
      "        [1.0582, 0.7633]])\n"
     ]
    }
   ],
   "source": [
    "# element wise addition\n",
    "z = x + y\n",
    "print(z)\n",
    "z = torch.add(x,y)\n",
    "print(z)\n",
    "# in place addition\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8274c2-38b4-4a6a-ac4a-a2f861b1e766",
   "metadata": {},
   "source": [
    "In pytorch every function with trailing underscore will do an inplace operation, will modify the variable that it is applied on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb33111d-ac58-4a1e-868c-7ae1e1277cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0869, -0.1482],\n",
      "        [-0.3593, -0.6663]])\n",
      "tensor([[-0.0869, -0.1482],\n",
      "        [-0.3593, -0.6663]])\n",
      "tensor([[0.0869, 0.1482],\n",
      "        [0.3593, 0.6663]])\n"
     ]
    }
   ],
   "source": [
    "# subtraction\n",
    "z = x - y\n",
    "print(z)\n",
    "z = torch.sub(x,y)\n",
    "print(z)\n",
    "# in place subtraction\n",
    "y.sub_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5a3bde1-4b7b-4dd7-bc9e-14275b4e6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0464, 0.0197],\n",
      "        [0.2511, 0.0646]])\n",
      "tensor([[0.0464, 0.0197],\n",
      "        [0.2511, 0.0646]])\n",
      "tensor([[0.0464, 0.0197],\n",
      "        [0.2511, 0.0646]])\n"
     ]
    }
   ],
   "source": [
    "# multiplying\n",
    "z = x * y\n",
    "print(z)\n",
    "z = torch.mul(x,y)\n",
    "print(z)\n",
    "y.mul_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4f905ac-9a2d-4f80-877d-83b5901873e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.5078,  6.7470],\n",
      "        [ 2.7830,  1.5008]])\n",
      "tensor([[11.5078,  6.7470],\n",
      "        [ 2.7830,  1.5008]])\n",
      "tensor([[0.0869, 0.1482],\n",
      "        [0.3593, 0.6663]])\n"
     ]
    }
   ],
   "source": [
    "# dividing\n",
    "z = x / y\n",
    "print(z)\n",
    "z = torch.div(x,y)\n",
    "print(z)\n",
    "y.div_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881f98c-0902-4681-a955-1a9a38643231",
   "metadata": {},
   "source": [
    "## Slicing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8519f00a-aee2-4715-9214-764d41c501e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tensor([[0.4085, 0.5641, 0.3783],\n",
      "        [0.6851, 0.0694, 0.3157],\n",
      "        [0.9099, 0.7571, 0.9710],\n",
      "        [0.9945, 0.6359, 0.7382],\n",
      "        [0.1441, 0.2253, 0.9300]])\n",
      "2. tensor([0.4085, 0.6851, 0.9099, 0.9945, 0.1441])\n",
      "3. tensor([0.6851, 0.0694, 0.3157])\n",
      "4. tensor(0.0694)\n",
      "5. 0.06942307949066162\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print('1.',x)\n",
    "# all rows and column 1\n",
    "print('2.',x[:, 0])\n",
    "# row 1 and all calumns\n",
    "print('3.',x[1, :])\n",
    "# tensor element on position 1 1\n",
    "print('4.',x[1, 1])\n",
    "# actual value, we can use this if we have only one element in our tensor\n",
    "print('5.',x[1, 1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e016d-c6eb-4f3b-a836-46526d0e55d3",
   "metadata": {},
   "source": [
    "## Reshaping a tensor\n",
    "\n",
    "Number of elements must still be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27d5cfd6-6fe5-4621-b86f-8e1c3481a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tensor([[0.5861, 0.2394, 0.6677, 0.9760],\n",
      "        [0.0062, 0.2056, 0.9046, 0.5796],\n",
      "        [0.2250, 0.2053, 0.1693, 0.7439],\n",
      "        [0.6966, 0.5818, 0.2002, 0.4839]])\n",
      "2. tensor([0.5861, 0.2394, 0.6677, 0.9760, 0.0062, 0.2056, 0.9046, 0.5796, 0.2250,\n",
      "        0.2053, 0.1693, 0.7439, 0.6966, 0.5818, 0.2002, 0.4839])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print('1.',x)\n",
    "# 1d vector\n",
    "y = x.view(16)\n",
    "print('2.',y)\n",
    "# by specifing -1 the PyTorch has to figure right size for itself\n",
    "# in this case it will be 2 by 8\n",
    "y = x.view(-1, 8)\n",
    "print('3.',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289400b-81a6-42ac-b92c-f1c693787c8f",
   "metadata": {},
   "source": [
    "## Converting from numpy to torch tensor and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82c7dc2d-d489-4fc9-8ce3-8db0ddc479fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "921d7f5a-5fc6-4697-84cb-abbaac001c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tensor([1., 1., 1., 1., 1.])\n",
      "2. [1. 1. 1. 1. 1.]\n",
      "3. <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print('1.', a)\n",
    "# converting tensor to numpy array\n",
    "b = a.numpy()\n",
    "print('2.', b)\n",
    "print('3.', type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671783ab-22a1-4f4c-aef8-282cf91c4743",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "we have to be careful because if the tensor is on the cpu and not the gpu then both objects will share the same memory location. This means that if we change one we will also change the other. If we modify b or a inplace then we will also modify another one. That's because they both point to the same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbef8ec9-86a1-4219-a709-6509e70aef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09a9fca7-813b-4626-9de5-a39a720cece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [1. 1. 1. 1. 1.]\n",
      "2. tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# converting numpy array to tensor\n",
    "# by default it will be data type float64\n",
    "a = np.ones(5)\n",
    "print('1.', a)\n",
    "b = torch.from_numpy(a)\n",
    "print('2.', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e00d5986-1844-4d21-87ae-e6738c59827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [2. 2. 2. 2. 2.]\n",
      "2. tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# same situation here, modifying one will also modify second one.\n",
    "# This happen only if tensor is on the cpu\n",
    "a += 1\n",
    "print('1.', a)\n",
    "print('2.', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d2483-507c-44f4-b3d6-704848413159",
   "metadata": {},
   "source": [
    "## Using GPU\n",
    "\n",
    "We can't convert a gpu tensor back to numpy because numpy can only handle cpu tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f1de89d-6569-4c75-8f3b-c726271e916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if we have gpu and then specifying device and creating tensor on gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    # specifing device\n",
    "    x = torch.ones(5, device=device)\n",
    "    y = torch.ones(5)\n",
    "    # moving our tensor to device\n",
    "    y = y.to(device)\n",
    "    # should be preformed on GPU and be much faster\n",
    "    z = x + y\n",
    "    # z.nupmy() will rise an error because numpy can only handle cpu tensors\n",
    "    # we have to change device to cpu\n",
    "    z = z.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55ea6fd9-a4d2-4537-8d81-46dde86776e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "2. tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "3. tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "print('1.', x)\n",
    "print('2.', y)\n",
    "print('3.', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7a4af-fe21-4a61-9490-d809974fb335",
   "metadata": {},
   "source": [
    "## Requires_gradf\n",
    "\n",
    "A lot of times when a tensor is created we see the argument requires_grad=True (by default it is False). After printing we will also see that requires_grad=True. This will tell PyTorch that it will need to calculate the gradients for this tensor later in our optimization steps. This means that whenever we have a variable in our model that we want to optimize then we need the gradients. So we need to specify requires_grad=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd712e61-b511-4f04-8537-2adb77af040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
