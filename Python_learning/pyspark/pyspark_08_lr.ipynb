{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Linear Regression\n",
    "\n",
    "Based on **Krish Naik** video: https://www.youtube.com/watch?v=_C8kWso4ne4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBricks version (no internet notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"data/tips.csv\" # Databricks file_location \"/FileStore/tables//test1.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# Theapplied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.csv(file_location, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Categorical Features\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCols=[\"sex\", \"smoker\", \"day\", \"time\"], outputCols=[\"sex_indexed\", \"smoker_indexed\", \"day_indexed\", \"time_indexed\"])\n",
    "df_r = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols=[ \n",
    "                'tip',\n",
    "                'size',\n",
    "                'sex_indexed',\n",
    "                'smoker_indexed',\n",
    "                'day_indexed',\n",
    "                'time_indexed'],\n",
    "                outputCol = \"Independent Features\")\n",
    "\n",
    "output = featureassembler.transform(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Independent Features|\n",
      "+--------------------+\n",
      "|[1.01,2.0,1.0,0.0...|\n",
      "|[1.66,3.0,0.0,0.0...|\n",
      "|[3.5,3.0,0.0,0.0,...|\n",
      "|[3.31,2.0,0.0,0.0...|\n",
      "|[3.61,4.0,1.0,0.0...|\n",
      "|[4.71,4.0,0.0,0.0...|\n",
      "|[2.0,2.0,0.0,0.0,...|\n",
      "|[3.12,4.0,0.0,0.0...|\n",
      "|[1.96,2.0,0.0,0.0...|\n",
      "|[3.23,2.0,0.0,0.0...|\n",
      "|[1.71,2.0,0.0,0.0...|\n",
      "|[5.0,4.0,1.0,0.0,...|\n",
      "|[1.57,2.0,0.0,0.0...|\n",
      "|[3.0,4.0,0.0,0.0,...|\n",
      "|[3.02,2.0,1.0,0.0...|\n",
      "|[3.92,2.0,0.0,0.0...|\n",
      "|[1.67,3.0,1.0,0.0...|\n",
      "|[3.71,3.0,0.0,0.0...|\n",
      "|[3.5,3.0,1.0,0.0,...|\n",
      "|(6,[0,1],[3.35,3.0])|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('Independent Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data = output.select(\"Independent Features\", \"total_bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|Independent Features|total_bill|\n",
      "+--------------------+----------+\n",
      "|[1.01,2.0,1.0,0.0...|     16.99|\n",
      "|[1.66,3.0,0.0,0.0...|     10.34|\n",
      "|[3.5,3.0,0.0,0.0,...|     21.01|\n",
      "|[3.31,2.0,0.0,0.0...|     23.68|\n",
      "|[3.61,4.0,1.0,0.0...|     24.59|\n",
      "|[4.71,4.0,0.0,0.0...|     25.29|\n",
      "|[2.0,2.0,0.0,0.0,...|      8.77|\n",
      "|[3.12,4.0,0.0,0.0...|     26.88|\n",
      "|[1.96,2.0,0.0,0.0...|     15.04|\n",
      "|[3.23,2.0,0.0,0.0...|     14.78|\n",
      "|[1.71,2.0,0.0,0.0...|     10.27|\n",
      "|[5.0,4.0,1.0,0.0,...|     35.26|\n",
      "|[1.57,2.0,0.0,0.0...|     15.42|\n",
      "|[3.0,4.0,0.0,0.0,...|     18.43|\n",
      "|[3.02,2.0,1.0,0.0...|     14.83|\n",
      "|[3.92,2.0,0.0,0.0...|     21.58|\n",
      "|[1.67,3.0,1.0,0.0...|     10.33|\n",
      "|[3.71,3.0,0.0,0.0...|     16.29|\n",
      "|[3.5,3.0,1.0,0.0,...|     16.97|\n",
      "|(6,[0,1],[3.35,3.0])|     20.65|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/28 07:31:48 WARN Instrumentation: [9fe546ef] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/06/28 07:31:48 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/06/28 07:31:48 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "# train test split\n",
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
    "regressor = LinearRegression(featuresCol = \"Independent Features\", labelCol=\"total_bill\")\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([3.2918, 3.5327, -0.7218, 2.284, -0.1233, -2.1187])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.070394653656759"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|Independent Features|total_bill|        prediction|\n",
      "+--------------------+----------+------------------+\n",
      "|(6,[0,1],[1.25,2.0])|     10.07| 12.25051403618172|\n",
      "|(6,[0,1],[1.75,2.0])|     17.82|13.896437645869074|\n",
      "| (6,[0,1],[2.0,2.0])|     12.69| 14.71939945071275|\n",
      "| (6,[0,1],[2.0,2.0])|     13.37| 14.71939945071275|\n",
      "| (6,[0,1],[2.0,3.0])|     16.31| 18.25205462986604|\n",
      "|(6,[0,1],[2.24,3.0])|     16.04| 19.04209796251597|\n",
      "| (6,[0,1],[2.5,4.0])|     18.35| 23.43063341870668|\n",
      "|(6,[0,1],[2.72,2.0])|     13.28| 17.08952944866254|\n",
      "| (6,[0,1],[3.0,2.0])|      14.0| 18.01124667008746|\n",
      "|[1.0,2.0,1.0,1.0,...|      5.75| 12.61966485036387|\n",
      "|[1.1,2.0,1.0,1.0,...|      12.9|13.318891212190229|\n",
      "|[1.17,2.0,0.0,1.0...|     32.83|14.271117703161945|\n",
      "|[1.32,2.0,0.0,0.0...|      9.68|12.357596128241656|\n",
      "|[1.36,3.0,1.0,0.0...|     18.64| 13.05805251860827|\n",
      "|[1.48,2.0,0.0,0.0...|      8.52|10.642216191395434|\n",
      "|[1.5,2.0,0.0,0.0,...|     19.08| 10.70805313578293|\n",
      "|[1.5,2.0,0.0,0.0,...|     12.46|12.703434201136512|\n",
      "|[1.5,2.0,0.0,1.0,...|     11.59|  15.3574272855556|\n",
      "|[1.5,2.0,0.0,1.0,...|     12.03|14.987385645666713|\n",
      "|[1.76,2.0,0.0,1.0...|     11.24| 16.21330756259302|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final comparison\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4104896090897727, 4.6501784594291475, 39.36079658675949)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Performance Metrics\n",
    "pred_results.r2, pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "\n",
    "How I ca  save this particular file in pickle format or in a temporary model pickle file. .save but check in documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
