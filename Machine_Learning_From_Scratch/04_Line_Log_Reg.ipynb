{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12c3326-2f7d-46ea-a70c-394a02133366",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression in 60 Lines\n",
    "\n",
    "Based on **Patric Loeber** video: https://www.youtube.com/watch?v=PC7cVBbU7UQ&t=16s\n",
    "\n",
    "Creating a base class from which inheritance will follow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb6c18-7fba-4599-9c04-a61268cfb79d",
   "metadata": {},
   "source": [
    "If we compare the code from 02_LinearRegression and 03_LogisticRegression then we will see that it's almost similar. Both classes have exactly the same init method and both habe almost the same fit method. In both classes we init our parameters and then we do the same gradient descent except that in the linear regression we have simply linear model for our approximated Y and in logistic regression we also have this linear model but then we also apply the sigmoid function. This same difference is in the predict method where in linear regression we simply apply linear model and in logistic regression we apply the linear model and then the sigmoid function. After applying the sigmoid function we can say if it's 1 or 1 and we also have a helper function for this but a lot of code is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b8ee537-4097-4055-8300-7fecdea84318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BaseRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate: float = 0.001, n_iters: int = 1000):\n",
    "        # Assign the variables\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        \n",
    "        # Weights and bias\n",
    "        self.weights, self.bias = None, None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # init parameters\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights, self.bias = np.zeros(n_features), 0\n",
    "        \n",
    "        # Minimiing loss, and finding the correct Weights and biases using Gradient Descent\n",
    "        for _ in range(self.n_iters):\n",
    "            y_predicted = self._approximation(X, self.weights, self.bias)\n",
    "            \n",
    "            # compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "            \n",
    "            # update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._predict(X, self.weights, self.bias)\n",
    "    \n",
    "    def _approximation(self, X, w, b):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _predict(self, X, w, b):\n",
    "        raise NotImplementedError()        \n",
    "                \n",
    "class LinearRegression(BaseRegression):\n",
    "    \n",
    "    def _approximation(self, X, w, b):\n",
    "        return np.dot(X, w) + b    \n",
    "            \n",
    "    def _predict(self, X, w, b):\n",
    "        return np.dot(X, w) + b\n",
    "    \n",
    "class LogisticRegression(BaseRegression):\n",
    "        \n",
    "    def _approximation(self, X, w, b):\n",
    "        linear_model = np.dot(X, w) + b\n",
    "        return self._sigmoid(linear_model)\n",
    "    \n",
    "    def _predict(self, X, w, b):\n",
    "        linear_model = np.dot(X, w) + b\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return np.array(y_predicted_cls)\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c4bcdb6-e05b-4502-8032-eecc99c73d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear reg Accuracy: 0.9253717934621964\n",
      "Logistic reg classification accuracy: 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Imports\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import datasets\n",
    "    \n",
    "    # Utils\n",
    "    def r2_score(y_true, y_pred):\n",
    "        corr_matrix = np.corrcoef(y_true, y_pred)\n",
    "        corr = corr_matrix[0, 1]\n",
    "        return corr ** 2\n",
    "    \n",
    "    def mean_squared_error(y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "    \n",
    "    # Linear Regression\n",
    "    X, y = datasets.make_regression(\n",
    "        n_samples=100, n_features=1, noise=20, random_state=4\n",
    "    )\n",
    "    \n",
    "    X_train,  X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=1234\n",
    "    )\n",
    "    \n",
    "    regressor = LinearRegression(learning_rate=0.01, n_iters=1000)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predictions = regressor.predict(X_test)\n",
    "    \n",
    "    accu = r2_score(y_test, predictions)\n",
    "    print(\"Linear reg Accuracy:\", accu)\n",
    "    \n",
    "    # Logistic reg\n",
    "    bc = datasets.load_breast_cancer()\n",
    "    X, y = bc.data, bc.target\n",
    "    \n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=1234\n",
    "    )\n",
    "    \n",
    "    regressor2 = LogisticRegression(learning_rate=0.0001, n_iters=1000)\n",
    "    regressor2.fit(X_train2, y_train2)\n",
    "    predictions2 = regressor2.predict(X_test2)\n",
    "    \n",
    "    print(\"Logistic reg classification accuracy:\", accuracy(y_test2, predictions2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
